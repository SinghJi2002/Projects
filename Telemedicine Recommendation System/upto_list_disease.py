# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uChEF7vWSWxyjCm4IAqfY0VghK5IamHJ
"""

#pip install chardet


import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import pandas as pd
import chardet

nltk.download('punkt')
nltk.download('stopwords')

def preprocess_text(input_text):
    cleaned_text = re.sub(r'[^\w\s]', '', input_text)
    cleaned_text = cleaned_text.lower()
    tokenized_words = word_tokenize(cleaned_text)
    stop_words = set(stopwords.words('english'))
    final_words = [word for word in tokenized_words if word not in stop_words]
    return final_words

df = pd.read_csv('dataset.csv')

df.head(4)

# prompt: read file in commonsympt.csv

with open('commonsympt.csv', 'rb') as f:
    result = chardet.detect(f.read())  # or readline if the file is large

# Print the detected character encoding
print(result['encoding'])

df_sympt = pd.read_csv('commonsympt.csv', encoding=result['encoding'])

with open('commonsympt.csv', 'rb') as f:
    encoding = chardet.detect(f.read())['encoding']
data = pd.read_csv('commonsympt.csv', encoding=encoding)
my_dataframe_sympt = pd.DataFrame(data)

def find_matching_tokens(tokens, dataframe):
    matched_tokens = []
    for token in tokens:
        matching_rows = dataframe[dataframe['Symptoms'].str.contains(token, case=False)]
        if not matching_rows.empty:
            matched_tokens.append(token)
    return matched_tokens

# Example usage
user_input=input("Enter your description: ")
#user_input = "A 45-year-old male with persistent cough , fatigue and a hearing sensitivity"
processed_tokens = preprocess_text(user_input)
#print(processed_tokens)
#matching_words = find_matching_tokens(processed_tokens, my_dataframe_sympt)
#print("Matched words:", matching_words)

processed_tokens

len(df2[:])

df2=df.fillna("null")
df2

report_disease = pd.DataFrame(columns=['disease_name'])
cnt = 0

list_from_df=[]

for i in  processed_tokens:
  for index1, row in df2.iterrows():

   list_from_df = row.tolist()
   for index in range(len(list_from_df)):

    if i.lower() == list_from_df[index].lower():
      flag=list_from_df[0]
      new_row = {'disease_name': row[0]}  # Replace 'disease_name' with desired column name
        # Add other columns if needed: new_row['column2'] = value2
      report_disease = report_disease.append(new_row, ignore_index=True)
      break

report_disease
report_disease = report_disease.drop_duplicates(subset='disease_name', inplace=False)

report_disease